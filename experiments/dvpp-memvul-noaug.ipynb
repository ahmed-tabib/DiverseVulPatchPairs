{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8152991,"sourceType":"datasetVersion","datasetId":4822204}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -r *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T17:17:49.612654Z","iopub.execute_input":"2024-04-21T17:17:49.612988Z","iopub.status.idle":"2024-04-21T17:17:50.575728Z","shell.execute_reply.started":"2024-04-21T17:17:49.612960Z","shell.execute_reply":"2024-04-21T17:17:50.574510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"lr\": 1e-4,\n    \"bsz\": 1,\n    \"epochs\": 50,\n    \"max_sequence_length\": 1024,\n    \"cwe_list\": [\"CWE-119\", \"CWE-125\", \"CWE-787\"]\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:17:50.578301Z","iopub.execute_input":"2024-04-21T17:17:50.578729Z","iopub.status.idle":"2024-04-21T17:17:50.584052Z","shell.execute_reply.started":"2024-04-21T17:17:50.578691Z","shell.execute_reply":"2024-04-21T17:17:50.582933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install wandb\n\n#import wandb\n#wandb.login(key='')\n#wandb.init(project='', config=config)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:17:50.585709Z","iopub.execute_input":"2024-04-21T17:17:50.586151Z","iopub.status.idle":"2024-04-21T17:18:23.561027Z","shell.execute_reply.started":"2024-04-21T17:17:50.586117Z","shell.execute_reply":"2024-04-21T17:18:23.559936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the basic performance metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\ndef calculate_perf_metrics(all_labels, all_predictions):\n    # evaluation scores\n    cm = confusion_matrix(all_labels, all_predictions)\n    accuracy = accuracy_score(all_labels, all_predictions)\n    precision = precision_score(all_labels, all_predictions)\n    recall = recall_score(all_labels, all_predictions)\n    f1 = f1_score(all_labels, all_predictions)\n\n    # Calculate false positive rate (FPR) and false negative rate (FNR)\n    tn, fp, fn, tp = cm.ravel()\n    fpr = fp / (fp + tn)\n    fnr = fn / (fn + tp)\n\n    return {\"accuracy\": accuracy,\n            \"precision\": precision,\n            \"recall\": recall,\n            \"f1-score\": f1,\n            \"FPR\": fpr,\n            \"FNR\": fnr\n           }","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:23.562409Z","iopub.execute_input":"2024-04-21T17:18:23.562752Z","iopub.status.idle":"2024-04-21T17:18:24.093712Z","shell.execute_reply.started":"2024-04-21T17:18:23.562719Z","shell.execute_reply":"2024-04-21T17:18:24.092580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, tokenizer, test_dataloader, max_steps=None):\n    all_labels = []\n    all_predictions = []\n\n    model.eval()\n    with torch.no_grad():\n        for step, samples in enumerate(test_dataloader):\n        \n            if max_steps:\n                if step >= max_steps:\n                    break\n            \n            # take each sample and set its label\n            inputs = samples['vuln'] + samples['patch']\n            labels = [1] * len(samples['vuln']) + [0] * len(samples['patch'])\n\n            # tokenize and pad all to same length\n            tokenizer_output = tokenizer(inputs,\n                                                 return_tensors='pt',\n                                                 padding='longest',\n                                                 truncation=True,\n                                                 max_length=config[\"max_sequence_length\"])\n\n            input_ids = tokenizer_output['input_ids'].to(device)\n            attention_mask = tokenizer_output['attention_mask'].to(device)\n\n            # get model predictions\n            outputs = torch.tensor([])\n\n            for i, a in zip(input_ids, attention_mask):\n                outputs = torch.cat( (outputs, model(i.unsqueeze(0), a.unsqueeze(0)).cpu()) )\n\n            all_labels += labels\n            all_predictions += torch.min(outputs, dim=1).indices.tolist()\n\n    metrics = calculate_perf_metrics(all_labels, all_predictions)\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:20:07.302892Z","iopub.execute_input":"2024-04-21T17:20:07.303260Z","iopub.status.idle":"2024-04-21T17:20:07.317255Z","shell.execute_reply.started":"2024-04-21T17:20:07.303233Z","shell.execute_reply":"2024-04-21T17:20:07.313775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pandas as pd\n\nclass DiverseVPPDataset(Dataset):\n    def __init__(self, path):\n        self.df = pd.read_csv(path)\n        self.df.drop(columns=self.df.columns[0], axis=1, inplace=True)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        return {\"vuln\": self.df.iloc[idx].loc[\"vuln\"],\n                \"patch\": self.df.iloc[idx].loc[\"patch\"]}\n    \n    def get_df(self):\n        return self.df\n    \n    def set_df(self, df):\n        self.df = df","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:24.114675Z","iopub.execute_input":"2024-04-21T17:18:24.114951Z","iopub.status.idle":"2024-04-21T17:18:28.113910Z","shell.execute_reply.started":"2024-04-21T17:18:24.114927Z","shell.execute_reply":"2024-04-21T17:18:28.112922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler\nfrom torch.utils.data.dataset import random_split\n\ndset = DiverseVPPDataset('/kaggle/input/diversevulpatchpairs/DiverseVulPatchPairs.csv')\n\ndf = dset.get_df().drop_duplicates(subset=['patch_hash'], keep=False)\ndf = df[df['cwe'].map(lambda e: any([(cwe in e) for cwe in config['cwe_list']]))]\n\ndset.set_df(df)\n\ntrain_dset, test_dset = random_split(dset, [0.85, 0.15])\n\nprint(\"Training set size: {} pairs, {} functions total.\".format(len(train_dset), len(train_dset)*2))\nprint(\"Testing set size:  {} pairs, {} functions total.\".format(len(test_dset), len(test_dset)*2))\nprint(\"Full set size:     {} pairs, {} functions total.\".format(len(dset), len(dset)*2))\n\ntrain_dataloader = DataLoader(dataset=train_dset,\n                              batch_size=config[\"bsz\"],\n                              shuffle=True,\n                              drop_last=False,\n                              num_workers=2)\n\ntest_dataloader = DataLoader(dataset=test_dset,\n                              batch_size=config[\"bsz\"],\n                              shuffle=False,\n                              drop_last=False,\n                              num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:28.115877Z","iopub.execute_input":"2024-04-21T17:18:28.117229Z","iopub.status.idle":"2024-04-21T17:18:30.537576Z","shell.execute_reply.started":"2024-04-21T17:18:28.117181Z","shell.execute_reply":"2024-04-21T17:18:30.536216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\n\ncheckpoint = \"Salesforce/codet5p-110m-embedding\"\n\ncodet5p_tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\ncodet5p_model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:30.538807Z","iopub.execute_input":"2024-04-21T17:18:30.539092Z","iopub.status.idle":"2024-04-21T17:18:39.789771Z","shell.execute_reply.started":"2024-04-21T17:18:30.539067Z","shell.execute_reply":"2024-04-21T17:18:39.788767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass VulnCodeT5(nn.Module):\n    \n    def __init__(self, codet5p):\n        super(VulnCodeT5, self).__init__()\n        \n        # codet5+ does its own embedding and normalization\n        # we want to customize this, so we only take the encoder\n        self.encoder = codet5p.encoder\n        \n        self.cls = nn.Sequential(\n            nn.Dropout(p=0.1),\n            nn.Linear(768, 3072),\n            nn.Tanh(),\n            nn.Dropout(p=0.1),\n            nn.Linear(3072, 3072),\n            nn.Linear(3072, 2)\n        )\n    \n    def forward(self, input_ids, attention_mask):\n        encoder_outputs = self.encoder(input_ids, attention_mask)\n        output = self.cls(encoder_outputs.last_hidden_state[:, 0, :])\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:39.791006Z","iopub.execute_input":"2024-04-21T17:18:39.791527Z","iopub.status.idle":"2024-04-21T17:18:39.802877Z","shell.execute_reply.started":"2024-04-21T17:18:39.791500Z","shell.execute_reply":"2024-04-21T17:18:39.801597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining the Training loop","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = VulnCodeT5(codet5p_model)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n\ncriterion = nn.BCEWithLogitsLoss()\n\n#print(eval_model(model, codet5p_tokenizer, test_dataloader, max_steps=250))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:20:11.072832Z","iopub.execute_input":"2024-04-21T17:20:11.073744Z","iopub.status.idle":"2024-04-21T17:20:27.930848Z","shell.execute_reply.started":"2024-04-21T17:20:11.073693Z","shell.execute_reply":"2024-04-21T17:20:27.929818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(config[\"epochs\"]):\n    model.train()\n    \n    all_labels_train = []\n    all_predictions_train = []\n    \n    for samples in train_dataloader:\n        # take each sample and set its label\n        inputs = samples['vuln'] + samples['patch']\n        labels = [1] * len(samples['vuln']) + [0] * len(samples['patch'])\n        \n        # tokenize and pad all to same length\n        tokenizer_output = codet5p_tokenizer(inputs,\n                                             return_tensors='pt',\n                                             padding='longest',\n                                             truncation=True,\n                                             max_length=config[\"max_sequence_length\"])\n        \n        input_ids = tokenizer_output['input_ids'].to(device)\n        attention_mask = tokenizer_output['attention_mask'].to(device)\n        labels = [[l, -1*(l-1)] for l in labels]\n        labels = torch.FloatTensor(labels)\n        \n        # forward pass\n        output = model(input_ids, attention_mask)\n            \n        # calc loss\n        loss = criterion(output.cpu(), labels)\n            \n        # backprop\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        #wandb.log({'epoch': epoch, 'loss': loss.item()})\n        \n        all_labels_train += torch.min(labels, dim=1).indices.tolist()\n        all_predictions_train += torch.min(output.cpu(), dim=1).indices.tolist()\n    \n    torch.save(model.state_dict(), './model.tmp')\n    \n    train_metrics = calculate_perf_metrics(all_labels_train, all_predictions_train)\n    test_metrics = eval_model(model, codet5p_tokenizer, test_dataloader, max_steps=250)\n    \n    train_metrics_wandb = {}\n    for k, v in train_metrics.items():\n        train_metrics_wandb[k+'_train'] = v\n    \n    test_metrics_wandb = {}\n    for k, v in test_metrics.items():\n        test_metrics_wandb[k+'_test'] = v\n        \n    #wandb.log(train_metrics_wandb)\n    #wandb.log(test_metrics_wandb)\n    \ntorch.save(model.state_dict(), './model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:40.781198Z","iopub.status.idle":"2024-04-21T17:18:40.781824Z","shell.execute_reply.started":"2024-04-21T17:18:40.781497Z","shell.execute_reply":"2024-04-21T17:18:40.781528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Eval","metadata":{}},{"cell_type":"code","source":"metrics = eval_model(model, codet5p_tokenizer, test_dataloader)\n#wandb.log({'final_metrics': metrics})\n#wandb.finish()\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:18:40.786716Z","iopub.status.idle":"2024-04-21T17:18:40.787279Z","shell.execute_reply.started":"2024-04-21T17:18:40.787016Z","shell.execute_reply":"2024-04-21T17:18:40.787039Z"},"trusted":true},"execution_count":null,"outputs":[]}]}